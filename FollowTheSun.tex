\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{fullpage}
\usepackage{float}
\usepackage{fullpage}
\usepackage{hyperref}
\usepackage{subcaption}

\begin{document}

\title{Follow the Sun: Learning North from Images}
\author{Brandon Minor \& Jack Morrison}
\maketitle

%%%%%%%%%%%%%%%%%%

\newcommand{\degrees}{$^\circ$ }

%%%%%%%%%%%%%%%%%%
\abstract{

Humans have navigated by the sun for millennia, relying on its predictable path across the sky to determine their own heading relative to north. We have applied Machine Learning algorithms to this practice in an attempt to do the same through images with only RGB data. Data was collected from three different areas in the US, all with different latitudes. A number of classification and regression algorithms were run on the different data sets, with varying success. 
%% Fill in more later
}

%%%%%%%%%%%%%%%%%%
\section{Experiment Setup}

%%
\subsection{Data Collection}
Datasets consisted of a series of images taken from one spot while rotating at least a full 360\degrees.
To train our parameters, our datasets need to include the heading and timestamp of every image. We produced an Android application to facilitate this process. Images were captured as fast as possible by the phone's camera and saved on external memory. Every photo taken had a related orientation vector that the phone registered at that timestamp. This vector was produced by the phone's magnetometer and registered the difference, in degrees, of the heading of the phone with respect to gravity and magnetic north. Images were only captured if the phone was nearly vertical, i.e.\ pitch of the phone was within $\pm$5\degrees of horizontal, as measured by the phone's internal sensors.

%%
\subsection{Software}
The processing for this project was done using the Python programming language and the scikit-learn \cite{scikit-learn} machine learning package. Plotting was done with the matplotlib library. All the code for this project can be found at \url{http://github.com/chachi/LearningNorth}.

%%%%%%%%%%%%%%%%%%
\section{Learning}

\begin{figure}[h!]
  \begin{subfigure}[!h]{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./features_img.eps}
    \caption{Sample image from the Woodley Park dataset}
    \label{fig:woodley_sample}
  \end{subfigure}
  \begin{subfigure}[!h]{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./Brightness_data.eps}
    \caption{Feature vector plot for image \ref{fig:woodley_sample}}
    \label{fig:woodley_features}
  \end{subfigure}
  \caption{Sample image and features used in learning}
\end{figure}

%%
\subsection{Features}
Each image in our dataset has over 900,000 pixels so feature extraction is necessary. To use every pixel of every image as a feature for learning would not only be computationally infeasible, it would also make learning extremely difficult. We chose to use a simple image brightness-based feature set for this image. To compute the feature vector, each image was converted to grayscale and scaled to $18x10$. The columns and rows of this ``thumbnail'' image were then summed to produce a rough plot of the shape of the brightness through the image. These vectors (one for the column sums, one for the row sums) were then concatenated to produce the feature vector you can see in Figure \ref{fig:woodley_features}.


\subsection{Labeling}
The true headings of the images were captured by the Android application along with the images. The magnetometer  registered magnetic north as 0\degrees and increases clockwise to 360\degrees. These headings were used as truth labels for learning and testing.

%%
\subsection{Classifier Algorithms}
The main objective of this project is to formulate a reliable classifier; if we can label the orientation of one set of images with low range of error, we would hope the classifier would work similarly for other data sets. As such, each classifier breaks the 360 compass degrees into twelve 30-degree increments before analysis. We used two different algorithms for classification: 
\begin{enumerate}[1.]
\item Support Vector Machines - We used polynomiall radial basis function, and linear kernels. Since there were twelve different incriments, the SVM treated the dataset as having 12 distinct classes. 
\item Decision Forests
\end{enumerate}
Squared error was used for training classifier algorithms.

%%
\subsection{Regression Algorithms}
Beyond this comparison of algorithms, we also performed regression function training. Our regression functions take our feature vectors and output an angle in degrees, with zero degrees being magnetic north. Our initial experiments used Linear Regression, using both LASSO and Ridge loss functions. 

%%%%%%%%%%%%%%%%%%
\section{Testing and Analysis}

The results presented below were run off a series of 11 datasets taken around the Woodley Park neighborhood in DC, around 4:00 in the afternoon. All total, there were 546 images with which to train on. Plots shown describe the error of each algorithm in different ways. The left scatterplot plots the image number (x-axis) with its associated error (y-axis). The right bar graph plots the average error of each heading from 0 (magnetic north) to 360 (...magnetic north). Note that classifier results were presented in 12\degrees classes; a label of 5 is equivalent to 60\degrees. 

%%
\subsection{Classifiers}
Our inintial results from our Classifier tests are presented below. 

\begin{center}
\begin{tabular}{l|c|c|c}
Classifier & Mean & Std Dev & Median\\
\hline
SVM - RBF & 5.811 & 4.346 & 5.0 \\
SVM - Polynomial, Deg 3 & 6.051 & 6.500 & 4.0 \\
SVM - Linear & 7.518 & 6.123 & 6.0 \\
Decision Trees & 7.121 & 6.552 & 5.0
\end{tabular}
\end{center}

%%RBF kernel
\begin{figure}[H]
  \begin{subfigure}[!h]{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./woodley/SVM_with_RBF_Kernel_heading_plot.eps}
  \end{subfigure}
  \begin{subfigure}[!h]{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./woodley/SVM_with_RBF_Kernel_heading_bar.eps}
  \end{subfigure}
  \caption{Error for SVM classification with an RBF kernel}
\end{figure}

%%Polynomial kernel
\begin{figure}[H]
  \begin{subfigure}[!h]{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./woodley/SVM_with_Polynomial_Kernel_heading_plot.eps}
  \end{subfigure}
  \begin{subfigure}[!h]{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./woodley/SVM_with_Polynomial_Kernel_heading_bar.eps}
  \end{subfigure}
  \caption{Error for SVM classification with a polynomial kernel}
\end{figure}

%%Linear kernel
\begin{figure}[H]
  \begin{subfigure}[!h]{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./woodley/Linear_SVM_heading_plot.eps}
  \end{subfigure}
  \begin{subfigure}[!h]{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./woodley/Linear_SVM_heading_bar.eps}
  \end{subfigure}
  \caption{Error for SVM classification with a linear kernel}
\end{figure}

Out of all of the SVM classifiers, the linear kernel proved to be the most unsuccessful for our purposes. Due to the non-linear nature of our data (See Fig. 1b), a linear kernel didn't describe data accurately. RBF kernel showed a highly regular classification pattern; one can actually see all 11 data sets represented in Figure 2, from the 11 peaks in the error. A similar thing can be said for the polynomial kernel, though this classifier was more successful than either the RBF or Linear kernel. 

%%Decision Trees
\begin{figure}[H]
  \begin{subfigure}[!h]{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./woodley/Decision_tree_heading_plot.eps}
  \end{subfigure}
  \begin{subfigure}[!h]{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./woodley/Decision_tree_heading_bar.eps}
  \end{subfigure}
  \caption{Error for Decision Tree Classification}
\end{figure}

Decision trees showed an error pattern similar to the linear kernel SVM; this could be due to the linearity that it operates by, and, again, the structure of the data provided. 

%%
\subsection{Regression}

\begin{center}
\begin{tabular}{l|c|c|c}
Regression & Mean & Std Dev & Median\\
\hline
Linear - LASSO & 61.618 & 49.551 & 48.272 \\
Linear - Ridge & 61.515 & 49.852 & 49.428
\end{tabular}
\end{center}

%% LASSO
\begin{figure}[H]
  \begin{subfigure}[!h]{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./woodley/LASSO_heading_plot.eps}
  \end{subfigure}
  \begin{subfigure}[!h]{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./woodley/LASSO_heading_bar.eps}
  \end{subfigure}
  \caption{Error for Linear Regression with LASSO}
\end{figure}

%% Ridge
\begin{figure}[H]
  \begin{subfigure}[!h]{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./woodley/Ridge_heading_plot.eps}
  \end{subfigure}
  \begin{subfigure}[!h]{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./woodley/Ridge_heading_bar.eps}
  \end{subfigure}
  \caption{Error for Linear Regression with Ridge}
\end{figure}

Both linear regressions exhibit similar behavior to the SVMs above; there's a dip in the error around 180\degrees, and a spike as the orientation approaches North from either direction. 

%%%%%%%%%%%%%%%%%%
\section{Further Work}

%%
\subsection{More Datasets}
Though most of our algorithms were run on a fairly large dataset (see Learning::Features), there is always room for more training and testing data. We would like to run the same tests on datasets with over one thousand images included. In addition, we would like to test on areas outside of DC;


%%
\subsection{More Features}
There are a couple of image analysis tools that we would like to utilize to extract some different features from our imgaes: 
\begin{enumerate}[1.]
\item Histogram of Oriented Gradients (HOG): Bins of pixels are formed into histograms representing the gradient of brightness levels in the bin. Feature count is dependent on the size of the bin. 
\begin{figure}[H]
\centering
\setlength\fboxsep{2pt}
\setlength\fboxrule{0pt}
\fbox{\includegraphics[scale=.3]{./HOGpic}}
\caption{
HOG
}
\end{figure}

\item RANSAC and shadow detection: using a point cloud of dark pixels, RANSAC is performed to get a basic linear function that fits the trend. This is then compared to other photos, and similar trends are classified similarly.
\begin{figure}[H]
\centering
\setlength\fboxsep{2pt}
\setlength\fboxrule{0pt}
\fbox{\includegraphics[scale=.3]{./RANSAC}}
\caption{
RANSAC (proposed)
}
\end{figure}

\end{enumerate}

\section{Conclusion}

The results of this project are encouraging. Using simple brightness metrics, we obtained rough heading measurements in images. Given the coarseness and simplicity of the extracted feature vectors, we did not expect such meaningful results. Moving forwards, more features and more datasets will be useful in improving prediction accuracy and reliability. The polynomial kernel's results were the most encouraging. This points to a likely nonlinear relationship between our features and labels which may be related to the periodic nature of our data, i.e.\ 0\degrees is actually adjacent to 360\degrees.

We feel that these results could have meaningful impact on areas when single photo location or viewing angle classification would be useful, such as in robotics or policing. We hope to continue improving our learning approaches using the promising results presented here.

\bibliographystyle{plain}
\bibliography{FollowTheSun}
\end{document}